{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3e490f4-c98b-4c60-88f3-339a2f38136a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time, os, sys\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "import random\n",
    "from tensorboardX import SummaryWriter\n",
    "import argparse\n",
    "from omegaconf import OmegaConf\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "from torchvision import transforms\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "plotly_layout = dict(margin=dict(l=20, r=20, t=20, b=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fec47165-1c08-44f5-9159-c72c20f3bafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../..')\n",
    "from loader import get_dataloader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac6f93d1-cfec-40eb-bb36-9521f0aa8e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraction_data: None\n",
      "MNIST split training | 5100\n",
      "no global Laplacian, normalized K, or distance matrix is precomputed\n"
     ]
    }
   ],
   "source": [
    "data_cfg = {\n",
    "    'dataset': 'MNIST',\n",
    "    'root': '../../dataset',\n",
    "    'batch_size': 100,\n",
    "    'n_workers': 4,\n",
    "    'split': 'training',\n",
    "    'shuffle': True,\n",
    "    'digits': [3],\n",
    "}\n",
    "\n",
    "dl = get_dataloader(data_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f34a6b03-236f-4fe3-96e7-868b394ce3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5100, 1, 28, 28]) torch.Size([5100])\n"
     ]
    }
   ],
   "source": [
    "data = dl.dataset.data\n",
    "targets = dl.dataset.targets\n",
    "\n",
    "print(data.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d1810f7-787f-4fe4-a0bb-b64d99fab02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15300, 1, 28, 28]) torch.Size([15300]) torch.Size([15300, 1, 42, 42, 10])\n"
     ]
    }
   ],
   "source": [
    "# Data configuration\n",
    "EPISODES_PER_IMAGE = 3      # Number of different episodes (i.e., different initial position) per same original image\n",
    "TIME_HORIZON = 10\n",
    "IMAGE_SIZE = 42\n",
    "RESIZE_DIM = 14             # Resize the image to this dimension\n",
    "\n",
    "# Set the velocity range for translation (in pixels per frame)\n",
    "VELOCITY_RANGE = (-2, 2)  # Velocities in x and y direction can range between -2 and 2\n",
    "\n",
    "# Repeat data for multiple episodes and create additional time dimension\n",
    "data = data.repeat_interleave(EPISODES_PER_IMAGE, 0)\n",
    "targets = targets.repeat_interleave(EPISODES_PER_IMAGE, 0)\n",
    "\n",
    "# Initialize new data tensor that will contain the transformed images of (1,56,56) size\n",
    "new_data = torch.zeros((data.shape[0], data.shape[1], IMAGE_SIZE, IMAGE_SIZE, TIME_HORIZON))\n",
    "\n",
    "print(data.shape, targets.shape, new_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "456d4ccb-6559-4304-9ff3-85bc18acbd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15300/15300 [00:08<00:00, 1876.52it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "resize_transform = transforms.Resize((RESIZE_DIM, RESIZE_DIM))\n",
    "\n",
    "for i_idx in trange(data.shape[0]):\n",
    "    # Random initial position for each episode\n",
    "    x_init = torch.randint(0, IMAGE_SIZE - RESIZE_DIM + 1, (1,)).item()\n",
    "    y_init = torch.randint(0, IMAGE_SIZE - RESIZE_DIM + 1, (1,)).item()\n",
    "    \n",
    "    # Calculate the maximum allowed velocities based on the initial position and the time horizon\n",
    "    max_x_velocity = min((IMAGE_SIZE - RESIZE_DIM - x_init) // (TIME_HORIZON - 1), VELOCITY_RANGE[1])\n",
    "    min_x_velocity = max(-(x_init // (TIME_HORIZON - 1)), VELOCITY_RANGE[0])                            # // before -. This is because -3//2 = -2, but we want -1.\n",
    "\n",
    "    max_y_velocity = min((IMAGE_SIZE - RESIZE_DIM - y_init) // (TIME_HORIZON - 1), VELOCITY_RANGE[1])\n",
    "    min_y_velocity = max(-(y_init // (TIME_HORIZON - 1)), VELOCITY_RANGE[0])                            # // before -. This is because -3//2 = -2, but we want -1.\n",
    "\n",
    "    # Ensure that there is a feasible velocity other than (0, 0)\n",
    "    assert min_x_velocity < max_x_velocity or min_y_velocity < max_y_velocity, f\"Invalid velocity range: {min_x_velocity}, {max_x_velocity}, {min_y_velocity}, {max_y_velocity}\"\n",
    "    \n",
    "    while True:\n",
    "        # Random initial velocities within the allowed range\n",
    "        x_velocity = torch.randint(min_x_velocity, max_x_velocity + 1, (1,)).item()\n",
    "        y_velocity = torch.randint(min_y_velocity, max_y_velocity + 1, (1,)).item()\n",
    "        if not (x_velocity == 0 and y_velocity == 0):\n",
    "            break\n",
    "\n",
    "\n",
    "    for j_idx in range(TIME_HORIZON):\n",
    "        # Random translation at each timestep within the allowed range\n",
    "        x_translate = min(max(x_init + x_velocity * j_idx, 0), IMAGE_SIZE - RESIZE_DIM)\n",
    "        y_translate = min(max(y_init + y_velocity * j_idx, 0), IMAGE_SIZE - RESIZE_DIM)\n",
    "        \n",
    "        # Resize and create a padded canvas\n",
    "        resized_img = resize_transform(data[i_idx, :, :, :]) # (1, 14, 14)\n",
    "        padded_img = torch.zeros([1,IMAGE_SIZE,IMAGE_SIZE])  # (1, 56, 56)\n",
    "\n",
    "        # Place the resized image on the canvas at the translated position\n",
    "        padded_img[:, x_translate:x_translate + RESIZE_DIM, y_translate:y_translate + RESIZE_DIM] = resized_img\n",
    "\n",
    "        # Update the dataset with the translated image\n",
    "        new_data[i_idx, :, :, :, j_idx] = padded_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f12a09c9-c572-4db1-9f24-d10793c10cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def draw_images(X):\n",
    "    \n",
    "#     fig=go.Figure(go.Image(z=X[:, :, :, 0].permute(1, 2, 0).repeat(1, 1, 3)*255))\n",
    "\n",
    "#     fig.layout.updatemenus = [\n",
    "#         {\n",
    "#             \"buttons\": [\n",
    "#                 {\n",
    "#                     \"args\": [None, {\"frame\": {\"duration\": 100, \"redraw\": True},\n",
    "#                                     \"fromcurrent\": True, \n",
    "#                                     \"transition\": {\"duration\": 1, \"easing\": \"quadratic-in-out\"}}],\n",
    "#                     \"label\": \"Play\",\n",
    "#                     \"method\": \"animate\"\n",
    "#                 },\n",
    "#                 {\n",
    "#                     \"args\": [[None], {\"frame\": {\"duration\": 0, \"redraw\": False},\n",
    "#                                     \"mode\": \"immediate\",\n",
    "#                                     \"transition\": {\"duration\": 0}}],\n",
    "#                     \"label\": \"Pause\",\n",
    "#                     \"method\": \"animate\"\n",
    "#                 }\n",
    "#             ],\n",
    "#             \"direction\": \"down\",\n",
    "#             \"pad\": {\"r\": 10, \"t\": 30},\n",
    "#             \"showactive\": False,\n",
    "#             \"type\": \"buttons\",\n",
    "#             \"x\": 0.1,\n",
    "#             \"xanchor\": \"right\",\n",
    "#             \"y\": 0,\n",
    "#             \"yanchor\": \"top\"\n",
    "#         }\n",
    "#     ]\n",
    "\n",
    "#     sliders_dict = {\n",
    "#         \"active\": 0,\n",
    "#         \"yanchor\": \"top\",\n",
    "#         \"xanchor\": \"left\",\n",
    "#         \"currentvalue\": {\n",
    "#             \"font\": {\"size\": 20},\n",
    "#             \"prefix\": \"Frame:\",\n",
    "#             \"visible\": True,\n",
    "#             \"xanchor\": \"left\"\n",
    "#         },\n",
    "#         \"transition\": {\"duration\": 1, \"easing\": \"cubic-in-out\"},\n",
    "#         \"pad\": {\"b\": 10, \"t\": 10},\n",
    "#         \"len\": 0.9,\n",
    "#         \"x\": 0.1,\n",
    "#         \"y\": 0,\n",
    "#         \"steps\": []\n",
    "#     }\n",
    "\n",
    "#     frames = [None]*TIME_HORIZON\n",
    "\n",
    "#     frame_idx = 0\n",
    "#     for i in range(TIME_HORIZON):\n",
    "#         frames[frame_idx] = go.Frame(data=[go.Image(z=X[:, :, :, i].permute(1, 2, 0).repeat(1, 1, 3)*255)], name=str(i))\n",
    "#         frame_idx += 1\n",
    "\n",
    "#         slider_step = {\n",
    "#             \"args\": [\n",
    "#                 [i],\n",
    "#                 {\"frame\": {\"duration\": 1, \"redraw\": True},\n",
    "#                 \"mode\": \"immediate\",\n",
    "#                 \"transition\": {\"duration\": 1}}\n",
    "#             ],\n",
    "#             \"label\": i+1,\n",
    "#             \"method\": \"animate\"\n",
    "#         }\n",
    "#         sliders_dict[\"steps\"].append(slider_step)\n",
    "#     fig.layout.sliders = [sliders_dict]\n",
    "\n",
    "#     fig.update(frames=frames)\n",
    "#     fig.update_layout(**plotly_layout, width=500, height=500)\n",
    "    \n",
    "#     return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "298131cb-5cc9-4cd8-b4ce-aa2afd9b0276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_images(data[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04bcdf1a-0bb2-4cc6-abee-aaf699152b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataset\n",
    "SAVE_PATH = '../../dataset_42/TranslatingMNIST/'\n",
    "os.makedirs(SAVE_PATH, exist_ok=True)\n",
    "\n",
    "torch.save({\n",
    "    'data': new_data[targets == 3],\n",
    "    'targets': targets[targets == 3]\n",
    "}, os.path.join(SAVE_PATH, 'TranslatingMNIST-digit=3.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('DLIsoLR')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "195f488e64f8a6bf3cb586da90b59a0fa46342450183d7ce5944e5e7f2dcd978"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
